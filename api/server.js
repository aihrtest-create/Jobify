import express from 'express'
import cors from 'cors'
import dotenv from 'dotenv'
import geminiService from './services/geminiService.js'
import openrouterService from './services/openrouterService.js'

// –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
dotenv.config()

const app = express()

// Middleware
app.use(cors({
  origin: process.env.FRONTEND_URL || '*',
  credentials: true
}))
app.use(express.json())
app.use(express.urlencoded({ extended: true }))

/**
 * Middleware –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤
 * @param {Object} req - –û–±—ä–µ–∫—Ç –∑–∞–ø—Ä–æ—Å–∞ Express
 * @param {Object} res - –û–±—ä–µ–∫—Ç –æ—Ç–≤–µ—Ç–∞ Express
 * @param {Function} next - –°–ª–µ–¥—É—é—â–∏–π middleware
 */
const requestLogger = (req, res, next) => {
  console.log(`${new Date().toISOString()} - ${req.method} ${req.path}`)
  next()
}

app.use(requestLogger)

/**
 * –ü–æ–ª—É—á–∏—Ç—å —Å–µ—Ä–≤–∏—Å LLM –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫
 * @param {Object} settings - –ù–∞—Å—Ç—Ä–æ–π–∫–∏ LLM
 * @returns {Object} –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Å–µ—Ä–≤–∏—Å LLM
 */
const getLLMService = (settings = {}) => {
  const { provider = 'gemini', geminiApiKey, openrouterApiKey } = settings
  
  if (provider === 'openrouter') {
    // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º API –∫–ª—é—á –¥–ª—è OpenRouter
    if (openrouterApiKey) {
      openrouterService.setApiKey(openrouterApiKey)
    }
    return openrouterService
  } else {
    // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º API –∫–ª—é—á –¥–ª—è Gemini
    if (geminiApiKey) {
      geminiService.setApiKey(geminiApiKey)
    } else if (process.env.GOOGLE_GEMINI_API_KEY) {
      // –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–ª—é—á –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∫–∞–∫ fallback
      geminiService.setApiKey(process.env.GOOGLE_GEMINI_API_KEY)
    }
    return geminiService
  }
}

// –ë–∞–∑–æ–≤—ã–µ –º–∞—Ä—à—Ä—É—Ç—ã
app.get('/', (req, res) => {
  res.json({ 
    message: 'Jobify.ai API Server',
    version: '1.0.0',
    status: 'running'
  })
})

/**
 * –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è API
 * @route GET /api/health
 */
app.get('/api/health', (req, res) => {
  res.json({
    status: 'healthy',
    timestamp: new Date().toISOString(),
    uptime: process.uptime()
  })
})

/**
 * –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —á–∞—Ç–∞
 * @param {Object} data - –î–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å–∞
 * @returns {Object} –†–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏
 */
const validateChatRequest = (data) => {
  const errors = []
  
  // –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
  if (!data.message || typeof data.message !== 'string' || data.message.trim().length === 0) {
    errors.push('Message is required and must be a non-empty string')
  }
  
  if (data.message && data.message.length > 5000) {
    errors.push('Message is too long (max 5000 characters)')
  }
  
  // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∂–∏–º
  if (data.mode && !['planning', 'interview'].includes(data.mode)) {
    errors.push('Mode must be either "planning" or "interview"')
  }
  
  // –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞
  if (data.conversationHistory && !Array.isArray(data.conversationHistory)) {
    errors.push('Conversation history must be an array')
  }
  
  return {
    isValid: errors.length === 0,
    errors
  }
}

/**
 * –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ —Å fallback –ª–æ–≥–∏–∫–æ–π
 * @param {Error} error - –û—à–∏–±–∫–∞
 * @param {string} context - –ö–æ–Ω—Ç–µ–∫—Å—Ç –æ—à–∏–±–∫–∏
 * @returns {Object} –û–±—ä–µ–∫—Ç –æ—à–∏–±–∫–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞
 */
const handleChatError = (error, context = 'Unknown') => {
  console.error(`Chat API error [${context}]:`, error)
  
  // –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –æ—à–∏–±–∫–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –æ—Ç–≤–µ—Ç
  if (error.message.includes('API key')) {
    return {
      success: false,
      error: 'API configuration error',
      canRetry: false,
      fallbackAvailable: false
    }
  }
  
  if (error.message.includes('quota') || error.message.includes('limit')) {
    return {
      success: false,
      error: 'API quota exceeded. Please try again later.',
      canRetry: true,
      fallbackAvailable: false
    }
  }
  
  if (error.message.includes('network') || error.message.includes('timeout')) {
    return {
      success: false,
      error: 'Network error. Please check your connection.',
      canRetry: true,
      fallbackAvailable: true
    }
  }
  
  return {
    success: false,
    error: 'Temporary service error. Please try again.',
    canRetry: true,
    fallbackAvailable: true,
    details: process.env.NODE_ENV === 'development' ? error.message : undefined
  }
}

/**
 * –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä–≤—å—é
 * @route POST /api/plan-interview
 */
app.post('/api/plan-interview', async (req, res) => {
  try {
    const { context = {}, settings = {} } = req.body
    
    console.log('Interview planning request:', {
      hasJob: !!context.jobText,
      hasResume: !!context.resumeText,
      jobLength: context.jobText?.length || 0,
      provider: settings.provider || 'gemini'
    })
    
    const llmService = getLLMService(settings)
    const result = await llmService.planInterview(context, settings)
    
    console.log('Interview plan generated:', {
      success: result.success,
      hasQuestions: !!result.data?.questions
    })
    
    res.json(result)
  } catch (error) {
    console.error('Interview planning error:', error)
    res.status(500).json({
      success: false,
      error: '–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏ –∏–Ω—Ç–µ—Ä–≤—å—é',
      details: error.message
    })
  }
})

/**
 * –ß–∞—Ç —Å LLM —á–µ—Ä–µ–∑ Gemini API —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä–µ–∂–∏–º–æ–≤
 * @route POST /api/chat
 */
app.post('/api/chat', async (req, res) => {
  try {
    const { 
      message, 
      context = {},
      conversationHistory = [],
      settings = {},
      mode = 'interview', // 'planning' | 'interview'
      interviewPlan = null
    } = req.body
    
    // –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    const validation = validateChatRequest(req.body)
    if (!validation.isValid) {
      return res.status(400).json({
        success: false,
        error: 'Validation failed',
        details: validation.errors
      })
    }

    // –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ LLM —Å fallback –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
    const {
      model = 'gemini-1.5-flash-8b',
      temperature = mode === 'planning' ? 0.3 : 0.7,
      maxTokens = mode === 'planning' ? 2000 : 1000
    } = settings

    // –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    console.log(`Chat API request [${mode}]:`, {
      messageLength: message.length,
      hasJob: !!context.jobText,
      hasResume: !!context.resumeText,
      hasPlan: !!interviewPlan,
      historyLength: conversationHistory.length,
      provider: settings.provider || 'gemini'
    })

    // –ü–æ–ª—É—á–∞–µ–º –Ω—É–∂–Ω—ã–π LLM —Å–µ—Ä–≤–∏—Å
    const llmService = getLLMService(settings)

    // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ LLM —Å retry –ª–æ–≥–∏–∫–æ–π
    let result
    let attempts = 0
    const maxAttempts = 3
    
    while (attempts < maxAttempts) {
      try {
        attempts++
        // –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—É—é –ª–æ–≥–∏–∫—É —á–∞—Ç–∞
        result = await llmService.sendChatMessage(message, conversationHistory, interviewPlan, {
          model,
          temperature,
          maxTokens
        })
        break
      } catch (error) {
        console.error(`Attempt ${attempts} failed:`, error.message)
        
        if (attempts === maxAttempts) {
          throw error
        }
        
        // –ñ–¥–µ–º –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π
        await new Promise(resolve => setTimeout(resolve, 1000 * attempts))
      }
    }
    
    // –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Ä–µ–∂–∏–º–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
    if (mode === 'planning' && result.success) {
      try {
        // –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –ø–ª–∞–Ω
        const planText = result.data.message
        const jsonMatch = planText.match(/\{[\s\S]*\}/)
        
        if (jsonMatch) {
          const planJson = JSON.parse(jsonMatch[0])
          result.data.plan = planJson
          result.data.planText = planText
        } else {
          console.warn('No JSON plan found in response, using text as is')
          result.data.planText = planText
        }
      } catch (parseError) {
        console.error('Failed to parse plan JSON:', parseError)
        // –ù–µ —Ñ–µ–π–ª–∏–º –∑–∞–ø—Ä–æ—Å, –ø—Ä–æ—Å—Ç–æ –æ—Ç–º–µ—á–∞–µ–º —á—Ç–æ –ø–ª–∞–Ω –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        result.data.planText = result.data.message
      }
    }
    
    // –ê–Ω–∞–ª–∏–∑ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∏–Ω—Ç–µ—Ä–≤—å—é
    if (mode === 'interview' && result.success) {
      const responseText = result.data.message.toLowerCase()
      result.data.isCompletionSuggested = responseText.includes('[interview_complete]')
      
      if (result.data.isCompletionSuggested) {
        // –û—á–∏—â–∞–µ–º –º–∞—Ä–∫–µ—Ä –∏–∑ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        result.data.message = result.data.message.replace(/\[INTERVIEW_COMPLETE\]/gi, '').trim()
      }
    }

    res.json(result)
  } catch (error) {
    const errorResponse = handleChatError(error, `${req.body.mode || 'interview'} mode`)
    res.status(500).json(errorResponse)
  }
})

/**
 * –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ —á–µ—Ä–µ–∑ Gemini API
 * @route POST /api/feedback
 */
app.post('/api/feedback', async (req, res) => {
  try {
    const { 
      messages, 
      context = {},
      settings = {}
    } = req.body

    if (!messages || messages.length === 0) {
      return res.status(400).json({
        success: false,
        error: 'Messages are required'
      })
    }

    // –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ñ–∏–¥–±–µ–∫–∞
    const {
      model = 'gemini-1.5-flash-8b',
      temperature = 0.3,
      maxTokens = 2000
    } = settings

    // –ü–æ–ª—É—á–∞–µ–º –Ω—É–∂–Ω—ã–π LLM —Å–µ—Ä–≤–∏—Å
    const llmService = getLLMService(settings)
    
    // –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å —á–µ—Ä–µ–∑ –≤—ã–±—Ä–∞–Ω–Ω—ã–π LLM
    const result = await llmService.generateFeedback(messages, context, {
      model,
      temperature,
      maxTokens
    })

    res.json(result)
  } catch (error) {
    console.error('Feedback API error:', error)
    res.status(500).json({
      success: false,
      error: 'Internal server error',
      details: error.message
    })
  }
})

/**
 * –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–æ–ø—Ä–æ–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–∏—Å—å–º–∞
 * @route POST /api/cover-letter
 */
app.post('/api/cover-letter', async (req, res) => {
  try {
    const { 
      context = {},
      settings = {}
    } = req.body

    if (!context.jobText) {
      return res.status(400).json({
        success: false,
        error: '–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –¥–∞–Ω–Ω—ã–µ –æ –≤–∞–∫–∞–Ω—Å–∏–∏'
      })
    }

    const { provider = 'gemini', model = 'gemini-1.5-flash-8b', temperature = 0.7, maxTokens = 1500 } = settings

    // –ü–æ–ª—É—á–∞–µ–º –Ω—É–∂–Ω—ã–π LLM —Å–µ—Ä–≤–∏—Å
    const llmService = getLLMService(settings)

    // –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —Å–æ–ø—Ä–æ–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–∏—Å—å–º–∞
    let systemPrompt = `–ù–∞–ø–∏—à–∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ–ø—Ä–æ–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø–∏—Å—å–º–æ –¥–ª—è –¥–∞–Ω–Ω–æ–π –≤–∞–∫–∞–Ω—Å–∏–∏.

–í–ê–ö–ê–ù–°–ò–Ø: ${context.jobText || '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–∞–∫–∞–Ω—Å–∏–∏ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∞'}
–†–ï–ó–Æ–ú–ï: ${context.resumeText || '–†–µ–∑—é–º–µ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ'}

–°–æ–∑–¥–∞–π –ø–∏—Å—å–º–æ –∏–∑ 3-4 –∞–±–∑–∞—Ü–µ–≤:
1. –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ –∏ –∏–Ω—Ç–µ—Ä–µ—Å –∫ –ø–æ–∑–∏—Ü–∏–∏
2. –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –æ–ø—ã—Ç –∏ –Ω–∞–≤—ã–∫–∏ –∏–∑ —Ä–µ–∑—é–º–µ
3. –ú–æ—Ç–∏–≤–∞—Ü–∏—è –∏ —Ü–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –∫–æ–º–ø–∞–Ω–∏–∏
4. –ü—Ä–∏–∑—ã–≤ –∫ –¥–µ–π—Å—Ç–≤–∏—é

–¢–æ–Ω: –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π, –Ω–æ –∂–∏–≤–æ–π. –ü–æ–¥—á–µ—Ä–∫–Ω–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º –≤–∞–∫–∞–Ω—Å–∏–∏.`
    
    const result = await llmService.sendMessage('–ù–∞–ø–∏—à–∏ —Å–æ–ø—Ä–æ–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø–∏—Å—å–º–æ', {
      model,
      temperature,
      maxTokens,
      systemPrompt,
      conversationHistory: []
    })

    res.json(result)
  } catch (error) {
    console.error('Cover letter API error:', error)
    res.status(500).json({
      success: false,
      error: 'Internal server error',
      details: error.message
    })
  }
})

/**
 * –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Gemini API (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
 * @route GET /api/test-gemini
 */
app.get('/api/test-gemini', async (req, res) => {
  try {
    const result = await geminiService.testConnection()
    res.json(result)
  } catch (error) {
    console.error('Gemini test error:', error)
    res.status(500).json({
      success: false,
      error: 'Internal server error',
      details: error.message
    })
  }
})

/**
 * –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä—É
 * @route POST /api/test-connection
 */
app.post('/api/test-connection', async (req, res) => {
  try {
    const { settings = {} } = req.body
    const { provider = 'gemini' } = settings
    
    console.log('Testing connection for provider:', provider)
    
    const llmService = getLLMService(settings)
    const result = await llmService.testConnection()
    
    res.json(result)
  } catch (error) {
    console.error('Connection test error:', error)
    res.status(500).json({
      success: false,
      error: 'Internal server error',
      details: error.message
    })
  }
})

// –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –º–∞—Ä—à—Ä—É—Ç–æ–≤
app.use('*', (req, res) => {
  res.status(404).json({
    success: false,
    error: 'Route not found'
  })
})

// –ì–ª–æ–±–∞–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫
app.use((error, req, res, next) => {
  console.error('Global error handler:', error)
  res.status(500).json({
    success: false,
    error: 'Internal server error'
  })
})

// –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è Vercel Functions
export default app

// –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞ —Ç–æ–ª—å–∫–æ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π —Å—Ä–µ–¥–µ
if (process.env.NODE_ENV !== 'production') {
  const PORT = process.env.PORT || 3001
  app.listen(PORT, () => {
    console.log(`üöÄ Jobify.ai API Server running on port ${PORT}`)
    console.log(`üìç Health check: http://localhost:${PORT}/api/health`)
  })
}
